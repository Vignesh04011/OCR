{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"Ex37EbAYf4SF","executionInfo":{"status":"ok","timestamp":1766079237678,"user_tz":-330,"elapsed":25289,"user":{"displayName":"Vignesh Vane","userId":"16339322031319135607"}},"outputId":"06f7741c-d30f-491f-e9ed-282a36e682b2","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!pip install -q transformers accelerate pillow pandas jiwer\n"],"metadata":{"id":"M2qeI9sXijYL","executionInfo":{"status":"ok","timestamp":1766079557897,"user_tz":-330,"elapsed":11343,"user":{"displayName":"Vignesh Vane","userId":"16339322031319135607"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["import os\n","import pandas as pd\n","from PIL import Image\n","import torch\n","from torch.utils.data import Dataset\n","from transformers import (\n","    TrOCRProcessor,\n","    VisionEncoderDecoderModel,\n","    TrainingArguments,\n","    Trainer\n",")\n","\n","# ===============================\n","# PATH CONFIG\n","# ===============================\n","BASE_DIR = \"/content/drive/MyDrive/handwriting_competition\"\n","IMAGES_DIR = os.path.join(BASE_DIR, \"images\")\n","\n","TRAIN_CSV = os.path.join(BASE_DIR, \"train.csv\")\n","VAL_CSV   = os.path.join(BASE_DIR, \"val.csv\")\n","\n","MODEL_NAME = \"microsoft/trocr-base-handwritten\"\n","OUTPUT_DIR = \"/content/trocr_answer_ocr\"\n","\n","# ===============================\n","# TRAIN CONFIG\n","# ===============================\n","BATCH_SIZE = 8\n","EPOCHS = 5\n","MAX_TEXT_LENGTH = 128\n","\n","device = torch.device(\"cuda\")\n","print(\"Using device:\", device)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mRaiux-dilaC","executionInfo":{"status":"ok","timestamp":1766080151811,"user_tz":-330,"elapsed":8,"user":{"displayName":"Vignesh Vane","userId":"16339322031319135607"}},"outputId":"7cb5ce58-1532-41c5-f7a0-db73dee3d78c"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]}]},{"cell_type":"code","source":["class OCRDataset(Dataset):\n","    def __init__(self, csv_file, processor):\n","        self.data = pd.read_csv(csv_file)\n","        self.processor = processor\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        row = self.data.iloc[idx]\n","\n","        image_path = row[\"image_path\"]\n","\n","        # Handle relative image paths\n","        if not os.path.isabs(image_path):\n","            image_path = os.path.join(IMAGES_DIR, image_path)\n","\n","        image = Image.open(image_path).convert(\"RGB\")\n","        text = str(row[\"text\"])\n","\n","        pixel_values = self.processor(\n","            image, return_tensors=\"pt\"\n","        ).pixel_values.squeeze(0)\n","\n","        labels = self.processor.tokenizer(\n","            text,\n","            padding=\"max_length\",\n","            max_length=MAX_TEXT_LENGTH,\n","            truncation=True,\n","            return_tensors=\"pt\"\n","        ).input_ids.squeeze(0)\n","\n","        labels[labels == self.processor.tokenizer.pad_token_id] = -100\n","\n","        return {\n","            \"pixel_values\": pixel_values,\n","            \"labels\": labels\n","        }\n"],"metadata":{"id":"x4BYqZvPinmz","executionInfo":{"status":"ok","timestamp":1766080153698,"user_tz":-330,"elapsed":9,"user":{"displayName":"Vignesh Vane","userId":"16339322031319135607"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["processor = TrOCRProcessor.from_pretrained(MODEL_NAME)\n","\n","model = VisionEncoderDecoderModel.from_pretrained(MODEL_NAME).to(device)\n","\n","# ===============================\n","# FREEZE VISION ENCODER\n","# ===============================\n","for param in model.encoder.parameters():\n","    param.requires_grad = False\n","\n","print(\"✅ Vision encoder frozen. Training decoder only.\")\n","\n","model.config.decoder_start_token_id = processor.tokenizer.cls_token_id\n","model.config.pad_token_id = processor.tokenizer.pad_token_id\n","model.config.vocab_size = model.config.decoder.vocab_size\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7qhaLycRipJO","executionInfo":{"status":"ok","timestamp":1766086531975,"user_tz":-330,"elapsed":12331,"user":{"displayName":"Vignesh Vane","userId":"16339322031319135607"}},"outputId":"ef322af0-da80-40de-c6ff-7acf788c8a54"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["✅ Vision encoder frozen. Training decoder only.\n"]}]},{"cell_type":"code","source":["train_dataset = OCRDataset(TRAIN_CSV, processor)\n","val_dataset   = OCRDataset(VAL_CSV, processor)\n","\n","print(\"Train samples:\", len(train_dataset))\n","print(\"Val samples:\", len(val_dataset))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KvpwFAhUiqNz","executionInfo":{"status":"ok","timestamp":1766080163906,"user_tz":-330,"elapsed":51,"user":{"displayName":"Vignesh Vane","userId":"16339322031319135607"}},"outputId":"0bea45d4-3f59-4568-f7fb-d6af207d52c8"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Train samples: 5511\n","Val samples: 518\n"]}]},{"cell_type":"code","source":["training_args = TrainingArguments(\n","    output_dir=OUTPUT_DIR,\n","    per_device_train_batch_size=BATCH_SIZE,\n","    per_device_eval_batch_size=BATCH_SIZE,\n","    eval_strategy=\"epoch\",     # IMPORTANT for older transformers\n","    save_strategy=\"epoch\",\n","    num_train_epochs=EPOCHS,\n","    fp16=True,\n","    logging_steps=100,\n","    save_total_limit=2,\n","    report_to=\"none\",\n","    remove_unused_columns=False\n",")\n"],"metadata":{"id":"tdONIr3cirhg","executionInfo":{"status":"ok","timestamp":1766080165437,"user_tz":-330,"elapsed":40,"user":{"displayName":"Vignesh Vane","userId":"16339322031319135607"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset\n",")\n"],"metadata":{"id":"Cn1TyVoTitaa","executionInfo":{"status":"ok","timestamp":1766080167049,"user_tz":-330,"elapsed":25,"user":{"displayName":"Vignesh Vane","userId":"16339322031319135607"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["trainer.train(resume_from_checkpoint=True)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":222},"id":"lbwmLXNiiu0C","executionInfo":{"status":"ok","timestamp":1766089596978,"user_tz":-330,"elapsed":3050057,"user":{"displayName":"Vignesh Vane","userId":"16339322031319135607"}},"outputId":"9d3daca2-2652-4732-a07b-58a47e5ff8b9"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stderr","text":["There were missing keys in the checkpoint model loaded: ['decoder.output_projection.weight'].\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='3445' max='3445' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3445/3445 50:29, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>3</td>\n","      <td>0.635100</td>\n","      <td>1.027230</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.297800</td>\n","      <td>0.829738</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.108500</td>\n","      <td>0.773998</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=3445, training_loss=0.23456071734601425, metrics={'train_runtime': 3031.5299, 'train_samples_per_second': 9.089, 'train_steps_per_second': 1.136, 'total_flos': 2.0654916127061705e+19, 'train_loss': 0.23456071734601425, 'epoch': 5.0})"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["!mkdir -p /content/drive/MyDrive/Custom_ocr\n","!cp -r /content/trocr_answer_ocr/checkpoint-3445 \\\n","      /content/drive/MyDrive/Custom_ocr/trocr_best_epoch5\n"],"metadata":{"id":"7ihwyqopJpUU","executionInfo":{"status":"ok","timestamp":1766089846736,"user_tz":-330,"elapsed":88434,"user":{"displayName":"Vignesh Vane","userId":"16339322031319135607"}}},"execution_count":24,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"/v2/external/notebooks/intro.ipynb","timestamp":1766079072742}],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}